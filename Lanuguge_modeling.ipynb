{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "2b9a2e75-2628-4ebe-8199-9f00939e2bb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "ad82eed5-6590-4916-a488-e96ecdc569e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0% [##############################] 100% | ETA: 00:00:00\n",
      "Total time elapsed: 00:00:02\n"
     ]
    }
   ],
   "source": [
    "import pyprind\n",
    "import pandas as pd\n",
    "import os\n",
    "import sys\n",
    "\n",
    "\n",
    "basepath = \"/home/hscuser/nlp/aclImdb_v1/aclImdb\"\n",
    "labels = {'pos':1, 'neg':0}\n",
    "pbar = pyprind.ProgBar(50000, stream = sys.stdout)\n",
    "df = pd.DataFrame()\n",
    "df_reviews = []\n",
    "df_sentiments = []\n",
    "for s in (\"test\", \"train\"):\n",
    "    for l in (\"pos\", \"neg\"):\n",
    "        path = os.path.join(basepath, s, l)\n",
    "        for file in sorted(os.listdir(path)):\n",
    "            with open(os.path.join(path, file), 'r', encoding = 'utf-8') as infile:\n",
    "                txt = infile.read()\n",
    "            df_reviews.append(txt)\n",
    "            df_sentiments.append(labels[l])\n",
    "            pbar.update()\n",
    "df['review'] = df_reviews\n",
    "df['sentiment'] = df_sentiments\n",
    "# df.columns = ['review','sentiment']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "ef81109f-12b0-440d-86f8-1625c45fe451",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 50000)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_reviews), len(df_sentiments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "cacbcd4e-12db-4210-ba99-065586205c8b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I went and saw this movie last night after bei...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Actor turned director Bill Paxton follows up h...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>As a recreational golfer with some knowledge o...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I saw this film in a sneak preview, and it is ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review  sentiment\n",
       "0  I went and saw this movie last night after bei...          1\n",
       "1  Actor turned director Bill Paxton follows up h...          1\n",
       "2  As a recreational golfer with some knowledge o...          1\n",
       "3  I saw this film in a sneak preview, and it is ...          1"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "8391ec87-5135-486b-9855-a49082064d17",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 2)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "80f3d1ad-b6b6-401b-bac7-f37be6d0ca11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 50000 entries, 0 to 49999\n",
      "Data columns (total 2 columns):\n",
      " #   Column     Non-Null Count  Dtype \n",
      "---  ------     --------------  ----- \n",
      " 0   review     50000 non-null  object\n",
      " 1   sentiment  50000 non-null  int64 \n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 781.4+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "89de72f9-ff3e-4c33-954e-592f9bfbcb70",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>50000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.500005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          sentiment\n",
       "count  50000.000000\n",
       "mean       0.500000\n",
       "std        0.500005\n",
       "min        0.000000\n",
       "25%        0.000000\n",
       "50%        0.500000\n",
       "75%        1.000000\n",
       "max        1.000000"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "35ba2e09-baaa-4566-89e2-d812f0519ad8",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(0)\n",
    "df = df.reindex(np.random.permutation(df.index))\n",
    "df.to_csv('movie_data.csv', index=False, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "218f4a55-7660-4703-889b-3716b7aaba46",
   "metadata": {},
   "source": [
    "### Introducing bag-of-words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "9902b1b2-223e-43b6-945d-29b5b3fc1e06",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "count = CountVectorizer(ngram_range=(1,1))\n",
    "docs = np.array(['The sun is shining is', 'The weather is sweet', 'The sun in shining, the weather is sweet', 'and one and one is two'])\n",
    "bag = count.fit_transform(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "e74be01d-d7dd-4104-96bd-31e91f8966ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'the': 7, 'sun': 5, 'is': 2, 'shining': 4, 'weather': 9, 'sweet': 6, 'in': 1, 'and': 0, 'one': 3, 'two': 8}\n",
      "{7: 'the', 5: 'sun', 2: 'is', 4: 'shining', 9: 'weather', 6: 'sweet', 1: 'in', 0: 'and', 3: 'one', 8: 'two'}\n"
     ]
    }
   ],
   "source": [
    "vocab = count.vocabulary_\n",
    "print(vocab)\n",
    "inv_vocab = {}\n",
    "for key, value in vocab.items():\n",
    "    inv_vocab[value] = key\n",
    "print(inv_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "bff67ceb-793a-44eb-89ca-3c79b322f059",
   "metadata": {},
   "outputs": [],
   "source": [
    "dump = bag.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "e024317d-5e83-44a8-a171-dc0b17e4ab75",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 2, 0, 1, 1, 0, 1, 0, 0],\n",
       "       [0, 0, 1, 0, 0, 0, 1, 1, 0, 1],\n",
       "       [0, 1, 1, 0, 1, 1, 1, 2, 0, 1],\n",
       "       [2, 0, 1, 2, 0, 0, 0, 0, 1, 0]])"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dump"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "755d5e15-a3d2-4b09-80c3-763c404d479d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 10)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dump.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "68e201f7-185e-44a6-be78-24f7c86f4a73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " is : 2, shining : 1, sun : 1, the : 1,\n",
      " is : 1, sweet : 1, the : 1, weather : 1,\n",
      " in : 1, is : 1, shining : 1, sun : 1, sweet : 1, the : 2, weather : 1,\n",
      " and : 2, is : 1, one : 2, two : 1,\n"
     ]
    }
   ],
   "source": [
    "for i in range(dump.shape[0]):\n",
    "    for j in range(dump.shape[1]):\n",
    "        if dump[i][j] >= 1:\n",
    "            print(f\" {inv_vocab[j]} : {dump[i][j]}\", end=\",\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f965dd6-e906-41b1-bcde-5965d3b7c207",
   "metadata": {},
   "source": [
    "## Term frequency - inverse document frequency "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "4020aa22-cd4f-4c65-9f66-d5f46d42c489",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.   0.   0.63 0.   0.48 0.48 0.   0.39 0.   0.  ]\n",
      " [0.   0.   0.38 0.   0.   0.   0.57 0.46 0.   0.57]\n",
      " [0.   0.43 0.22 0.   0.34 0.34 0.34 0.55 0.   0.34]\n",
      " [0.66 0.   0.17 0.66 0.   0.   0.   0.   0.33 0.  ]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "\n",
    "tfidf = TfidfTransformer(\n",
    "    use_idf = True,\n",
    "    norm = 'l2',\n",
    "    smooth_idf = True\n",
    ")\n",
    "\n",
    "np.set_printoptions(precision = 2)\n",
    "print(tfidf.fit_transform(count.fit_transform(docs)).toarray())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1aef3fb-bc68-4d12-ae0f-c9d641971fd2",
   "metadata": {},
   "source": [
    "## cleaning text data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "420d4fb4-f606-4a0b-856b-0cd9d05c36a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Actor turned director Bill Paxton follows up his promising debut, the Gothic-horror \"Frailty\", with this family friendly sports drama about the 1913 U.S. Open where a young American caddy rises from his humble background to play against his Bristish idol in what was dubbed as \"The Greatest Game Ever Played.\" I\\'m no fan of golf, and these scrappy underdog sports flicks are a dime a dozen (most recently done to grand effect with \"Miracle\" and \"Cinderella Man\"), but some how this film was enthralling all the same.<br /><br />The film starts with some creative opening credits (imagine a Disneyfied version of the animated opening credits of HBO\\'s \"Carnivale\" and \"Rome\"), but lumbers along slowly for its first by-the-numbers hour. Once the action moves to the U.S. Open things pick up very well. Paxton does a nice job and shows a knack for effective directorial flourishes (I loved the rain-soaked montage of the action on day two of the open) that propel the plot further or add some unexpected psychological depth to the proceedings. There\\'s some compelling character development when the British Harry Vardon is haunted by images of the aristocrats in black suits and top hats who destroyed his family cottage as a child to make way for a golf course. He also does a good job of visually depicting what goes on in the players\\' heads under pressure. Golf, a painfully boring sport, is brought vividly alive here. Credit should also be given the set designers and costume department for creating an engaging period-piece atmosphere of London and Boston at the beginning of the twentieth century.<br /><br />You know how this is going to end not only because it\\'s based on a true story but also because films in this genre follow the same template over and over, but Paxton puts on a better than average show and perhaps indicates more talent behind the camera than he ever had in front of it. Despite the formulaic nature, this is a nice and easy film to root for that deserves to find an audience.'"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[1, 'review']#[-50:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "0733b800-1e39-45ba-b7e9-33db4d0ad51c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if we see above cell there were many html tags which we does not need. we need to remove them.\n",
    "# sometimes there might be some emotions like smilie's like :), they add/ help us in the sentiment analysis so we need to keep them.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "d451e90d-f539-4c46-a3ef-af81d3a1c8b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def preprocessor(text):\n",
    "    text = re.sub('<[^>]*>', '', text)\n",
    "    emoticons = re.findall('(?::|;|=)(?:-)?(?:\\)|\\(|D|P)', \n",
    "                            text)\n",
    "    text = (re.sub('[\\W]+', ' ', text.lower()) + ' '.join(emoticons).replace('-',''))\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "98417ba9-7ece-46a6-9e80-17bae1402caf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1942"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(preprocessor(df['review'][1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "73ce5e46-d0f9-4334-8da1-31fd6a529430",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2004"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df['review'][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "317c3fb5-5634-4651-94cb-222cdcb8bbf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['review'] = df['review'].apply(preprocessor)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1afd3c86-d069-4ccb-a183-09d947eba184",
   "metadata": {},
   "source": [
    "## processing documents into tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "af447d8b-4fe2-4e95-82da-bdd197e40417",
   "metadata": {},
   "outputs": [],
   "source": [
    "## afer cleaning the data, we need to represent the data in the form that our model understand that is called as tokenization\n",
    "## to do tokenization, for now we use the .split() method for the string which separates the words with whitespace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "f1c9a4e9-264b-491a-b470-a5f9b7baef46",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenizer(text):\n",
    "    return text.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "e3fbb15e-80fb-4d7c-b55c-d18571ef73c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['hey', 'how', 'are', 'you', 'today']"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer(\"hey how are you today\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "70d6f1f7-5900-4f8e-9d1b-f4e351a1e690",
   "metadata": {},
   "outputs": [],
   "source": [
    "## there is also a usefull techinique is word stemming, which is the process of transforming a word into its root form.\n",
    "## it allows us to map related words to the same stem.\n",
    "## this stemming algo is called as the porter stemming algo\n",
    "## this is available in the nltk lib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "656117e5-a856-4abb-a9b8-51fc6057b3da",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem.porter import PorterStemmer\n",
    "\n",
    "porter = PorterStemmer()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "9d75dd10-299d-4b20-9750-47f3ec7b551f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['run', 'is', 'good', 'for', 'health']"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def tokenizer_porter(text):\n",
    "    return [porter.stem(word) for word in text.split()]\n",
    "tokenizer_porter(\"running is good for health\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "9e1ccf6e-3ea1-4be8-b2d3-244f9f48c52f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/hscuser/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "\n",
    "nltk.download(\"stopwords\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "b089aabe-58eb-41ee-92b6-c89daf4f0664",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['runner', 'like', 'runn', 'run', 'lot']"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "\n",
    "stop = stopwords.words(\"english\")\n",
    "[ w for w in tokenizer_porter('a runner likes runnning and runs a lot') if w not in stop]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "0efd5ba6-6b5b-4dc4-8226-f2b694196a06",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Training a logistic regression model for document classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "fe12089b-32cc-4f90-9739-35d5a69a3909",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = df.loc[:25000, 'review'].values\n",
    "y_train = df.loc[:25000, 'sentiment'].values\n",
    "X_test = df.loc[25000:, 'review'].values\n",
    "y_test = df.loc[25000:, 'sentiment'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "6b33420d-4962-4bfd-84bc-c1b7d5717e5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use a gridsearchcv to find a optimal set of parameters for our logistic regression model using 5-fold stratified cross-validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "6de017cc-d332-4e76-bb36-79f0fd389e00",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hscuser/nlp/env/nllp/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:517: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n",
      "[CV] END clf__C=1.0, clf__penalty=l2, vect__ngram_range=(1, 1), vect__stop_words=None, vect__tokenizer=<function tokenizer at 0x78a20521ce50>; total time=   1.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hscuser/nlp/env/nllp/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:517: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END clf__C=1.0, clf__penalty=l2, vect__ngram_range=(1, 1), vect__stop_words=None, vect__tokenizer=<function tokenizer at 0x78a20521ce50>; total time=   1.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hscuser/nlp/env/nllp/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:517: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END clf__C=1.0, clf__penalty=l2, vect__ngram_range=(1, 1), vect__stop_words=None, vect__tokenizer=<function tokenizer at 0x78a20521ce50>; total time=   1.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hscuser/nlp/env/nllp/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:517: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END clf__C=1.0, clf__penalty=l2, vect__ngram_range=(1, 1), vect__stop_words=None, vect__tokenizer=<function tokenizer at 0x78a20521ce50>; total time=   1.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hscuser/nlp/env/nllp/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:517: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END clf__C=1.0, clf__penalty=l2, vect__ngram_range=(1, 1), vect__stop_words=None, vect__tokenizer=<function tokenizer at 0x78a20521ce50>; total time=   1.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hscuser/nlp/env/nllp/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:517: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END clf__C=1.0, clf__penalty=l2, vect__ngram_range=(1, 1), vect__stop_words=None, vect__tokenizer=<function tokenizer_porter at 0x78a205644040>; total time=  37.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hscuser/nlp/env/nllp/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:517: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END clf__C=1.0, clf__penalty=l2, vect__ngram_range=(1, 1), vect__stop_words=None, vect__tokenizer=<function tokenizer_porter at 0x78a205644040>; total time=  39.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hscuser/nlp/env/nllp/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:517: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END clf__C=1.0, clf__penalty=l2, vect__ngram_range=(1, 1), vect__stop_words=None, vect__tokenizer=<function tokenizer_porter at 0x78a205644040>; total time=  42.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hscuser/nlp/env/nllp/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:517: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END clf__C=1.0, clf__penalty=l2, vect__ngram_range=(1, 1), vect__stop_words=None, vect__tokenizer=<function tokenizer_porter at 0x78a205644040>; total time=  41.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hscuser/nlp/env/nllp/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:517: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END clf__C=1.0, clf__penalty=l2, vect__ngram_range=(1, 1), vect__stop_words=None, vect__tokenizer=<function tokenizer_porter at 0x78a205644040>; total time=  41.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hscuser/nlp/env/nllp/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:517: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END clf__C=10.0, clf__penalty=l2, vect__ngram_range=(1, 1), vect__stop_words=None, vect__tokenizer=<function tokenizer at 0x78a20521ce50>; total time=   2.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hscuser/nlp/env/nllp/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:517: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END clf__C=10.0, clf__penalty=l2, vect__ngram_range=(1, 1), vect__stop_words=None, vect__tokenizer=<function tokenizer at 0x78a20521ce50>; total time=   2.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hscuser/nlp/env/nllp/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:517: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END clf__C=10.0, clf__penalty=l2, vect__ngram_range=(1, 1), vect__stop_words=None, vect__tokenizer=<function tokenizer at 0x78a20521ce50>; total time=   2.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hscuser/nlp/env/nllp/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:517: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END clf__C=10.0, clf__penalty=l2, vect__ngram_range=(1, 1), vect__stop_words=None, vect__tokenizer=<function tokenizer at 0x78a20521ce50>; total time=   2.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hscuser/nlp/env/nllp/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:517: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END clf__C=10.0, clf__penalty=l2, vect__ngram_range=(1, 1), vect__stop_words=None, vect__tokenizer=<function tokenizer at 0x78a20521ce50>; total time=   2.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hscuser/nlp/env/nllp/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:517: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END clf__C=10.0, clf__penalty=l2, vect__ngram_range=(1, 1), vect__stop_words=None, vect__tokenizer=<function tokenizer_porter at 0x78a205644040>; total time=  41.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hscuser/nlp/env/nllp/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:517: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END clf__C=10.0, clf__penalty=l2, vect__ngram_range=(1, 1), vect__stop_words=None, vect__tokenizer=<function tokenizer_porter at 0x78a205644040>; total time=  41.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hscuser/nlp/env/nllp/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:517: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END clf__C=10.0, clf__penalty=l2, vect__ngram_range=(1, 1), vect__stop_words=None, vect__tokenizer=<function tokenizer_porter at 0x78a205644040>; total time=  41.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hscuser/nlp/env/nllp/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:517: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END clf__C=10.0, clf__penalty=l2, vect__ngram_range=(1, 1), vect__stop_words=None, vect__tokenizer=<function tokenizer_porter at 0x78a205644040>; total time=  43.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hscuser/nlp/env/nllp/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:517: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END clf__C=10.0, clf__penalty=l2, vect__ngram_range=(1, 1), vect__stop_words=None, vect__tokenizer=<function tokenizer_porter at 0x78a205644040>; total time=  42.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hscuser/nlp/env/nllp/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:517: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END clf__C=1.0, clf__penalty=l2, vect__ngram_range=(1, 1), vect__norm=None, vect__stop_words=None, vect__tokenizer=<function tokenizer at 0x78a20521ce50>, vect__use_idf=False; total time=   7.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hscuser/nlp/env/nllp/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:517: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END clf__C=1.0, clf__penalty=l2, vect__ngram_range=(1, 1), vect__norm=None, vect__stop_words=None, vect__tokenizer=<function tokenizer at 0x78a20521ce50>, vect__use_idf=False; total time=   6.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hscuser/nlp/env/nllp/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:517: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END clf__C=1.0, clf__penalty=l2, vect__ngram_range=(1, 1), vect__norm=None, vect__stop_words=None, vect__tokenizer=<function tokenizer at 0x78a20521ce50>, vect__use_idf=False; total time=   5.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hscuser/nlp/env/nllp/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:517: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END clf__C=1.0, clf__penalty=l2, vect__ngram_range=(1, 1), vect__norm=None, vect__stop_words=None, vect__tokenizer=<function tokenizer at 0x78a20521ce50>, vect__use_idf=False; total time=   5.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hscuser/nlp/env/nllp/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:517: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END clf__C=1.0, clf__penalty=l2, vect__ngram_range=(1, 1), vect__norm=None, vect__stop_words=None, vect__tokenizer=<function tokenizer at 0x78a20521ce50>, vect__use_idf=False; total time=   6.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hscuser/nlp/env/nllp/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:517: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END clf__C=1.0, clf__penalty=l2, vect__ngram_range=(1, 1), vect__norm=None, vect__stop_words=None, vect__tokenizer=<function tokenizer_porter at 0x78a205644040>, vect__use_idf=False; total time=  45.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hscuser/nlp/env/nllp/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:517: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END clf__C=1.0, clf__penalty=l2, vect__ngram_range=(1, 1), vect__norm=None, vect__stop_words=None, vect__tokenizer=<function tokenizer_porter at 0x78a205644040>, vect__use_idf=False; total time=  45.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hscuser/nlp/env/nllp/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:517: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END clf__C=1.0, clf__penalty=l2, vect__ngram_range=(1, 1), vect__norm=None, vect__stop_words=None, vect__tokenizer=<function tokenizer_porter at 0x78a205644040>, vect__use_idf=False; total time=  45.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hscuser/nlp/env/nllp/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:517: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END clf__C=1.0, clf__penalty=l2, vect__ngram_range=(1, 1), vect__norm=None, vect__stop_words=None, vect__tokenizer=<function tokenizer_porter at 0x78a205644040>, vect__use_idf=False; total time=  45.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hscuser/nlp/env/nllp/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:517: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END clf__C=1.0, clf__penalty=l2, vect__ngram_range=(1, 1), vect__norm=None, vect__stop_words=None, vect__tokenizer=<function tokenizer_porter at 0x78a205644040>, vect__use_idf=False; total time=  45.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hscuser/nlp/env/nllp/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:517: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END clf__C=10.0, clf__penalty=l2, vect__ngram_range=(1, 1), vect__norm=None, vect__stop_words=None, vect__tokenizer=<function tokenizer at 0x78a20521ce50>, vect__use_idf=False; total time=   7.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hscuser/nlp/env/nllp/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:517: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END clf__C=10.0, clf__penalty=l2, vect__ngram_range=(1, 1), vect__norm=None, vect__stop_words=None, vect__tokenizer=<function tokenizer at 0x78a20521ce50>, vect__use_idf=False; total time=   7.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hscuser/nlp/env/nllp/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:517: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END clf__C=10.0, clf__penalty=l2, vect__ngram_range=(1, 1), vect__norm=None, vect__stop_words=None, vect__tokenizer=<function tokenizer at 0x78a20521ce50>, vect__use_idf=False; total time=   6.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hscuser/nlp/env/nllp/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:517: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END clf__C=10.0, clf__penalty=l2, vect__ngram_range=(1, 1), vect__norm=None, vect__stop_words=None, vect__tokenizer=<function tokenizer at 0x78a20521ce50>, vect__use_idf=False; total time=   7.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hscuser/nlp/env/nllp/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:517: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END clf__C=10.0, clf__penalty=l2, vect__ngram_range=(1, 1), vect__norm=None, vect__stop_words=None, vect__tokenizer=<function tokenizer at 0x78a20521ce50>, vect__use_idf=False; total time=   6.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hscuser/nlp/env/nllp/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:517: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END clf__C=10.0, clf__penalty=l2, vect__ngram_range=(1, 1), vect__norm=None, vect__stop_words=None, vect__tokenizer=<function tokenizer_porter at 0x78a205644040>, vect__use_idf=False; total time=  45.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hscuser/nlp/env/nllp/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:517: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END clf__C=10.0, clf__penalty=l2, vect__ngram_range=(1, 1), vect__norm=None, vect__stop_words=None, vect__tokenizer=<function tokenizer_porter at 0x78a205644040>, vect__use_idf=False; total time=  46.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hscuser/nlp/env/nllp/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:517: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END clf__C=10.0, clf__penalty=l2, vect__ngram_range=(1, 1), vect__norm=None, vect__stop_words=None, vect__tokenizer=<function tokenizer_porter at 0x78a205644040>, vect__use_idf=False; total time=  46.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hscuser/nlp/env/nllp/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:517: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END clf__C=10.0, clf__penalty=l2, vect__ngram_range=(1, 1), vect__norm=None, vect__stop_words=None, vect__tokenizer=<function tokenizer_porter at 0x78a205644040>, vect__use_idf=False; total time=  45.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hscuser/nlp/env/nllp/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:517: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END clf__C=10.0, clf__penalty=l2, vect__ngram_range=(1, 1), vect__norm=None, vect__stop_words=None, vect__tokenizer=<function tokenizer_porter at 0x78a205644040>, vect__use_idf=False; total time=  45.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hscuser/nlp/env/nllp/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:517: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: #000;\n",
       "  --sklearn-color-text-muted: #666;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-2 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-2 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-2 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: flex;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "  align-items: start;\n",
       "  justify-content: space-between;\n",
       "  gap: 0.5em;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 label.sk-toggleable__label .caption {\n",
       "  font-size: 0.6rem;\n",
       "  font-weight: lighter;\n",
       "  color: var(--sklearn-color-text-muted);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content {\n",
       "  display: none;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  overflow: visible;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-2 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-2 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-2 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-2 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-2 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 0.5em;\n",
       "  text-align: center;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-2 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".estimator-table summary {\n",
       "    padding: .5rem;\n",
       "    font-family: monospace;\n",
       "    cursor: pointer;\n",
       "}\n",
       "\n",
       ".estimator-table details[open] {\n",
       "    padding-left: 0.1rem;\n",
       "    padding-right: 0.1rem;\n",
       "    padding-bottom: 0.3rem;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table {\n",
       "    margin-left: auto !important;\n",
       "    margin-right: auto !important;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table tr:nth-child(odd) {\n",
       "    background-color: #fff;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table tr:nth-child(even) {\n",
       "    background-color: #f6f6f6;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table tr:hover {\n",
       "    background-color: #e0e0e0;\n",
       "}\n",
       "\n",
       ".estimator-table table td {\n",
       "    border: 1px solid rgba(106, 105, 104, 0.232);\n",
       "}\n",
       "\n",
       ".user-set td {\n",
       "    color:rgb(255, 94, 0);\n",
       "    text-align: left;\n",
       "}\n",
       "\n",
       ".user-set td.value pre {\n",
       "    color:rgb(255, 94, 0) !important;\n",
       "    background-color: transparent !important;\n",
       "}\n",
       "\n",
       ".default td {\n",
       "    color: black;\n",
       "    text-align: left;\n",
       "}\n",
       "\n",
       ".user-set td i,\n",
       ".default td i {\n",
       "    color: black;\n",
       "}\n",
       "\n",
       ".copy-paste-icon {\n",
       "    background-image: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHZpZXdCb3g9IjAgMCA0NDggNTEyIj48IS0tIUZvbnQgQXdlc29tZSBGcmVlIDYuNy4yIGJ5IEBmb250YXdlc29tZSAtIGh0dHBzOi8vZm9udGF3ZXNvbWUuY29tIExpY2Vuc2UgLSBodHRwczovL2ZvbnRhd2Vzb21lLmNvbS9saWNlbnNlL2ZyZWUgQ29weXJpZ2h0IDIwMjUgRm9udGljb25zLCBJbmMuLS0+PHBhdGggZD0iTTIwOCAwTDMzMi4xIDBjMTIuNyAwIDI0LjkgNS4xIDMzLjkgMTQuMWw2Ny45IDY3LjljOSA5IDE0LjEgMjEuMiAxNC4xIDMzLjlMNDQ4IDMzNmMwIDI2LjUtMjEuNSA0OC00OCA0OGwtMTkyIDBjLTI2LjUgMC00OC0yMS41LTQ4LTQ4bDAtMjg4YzAtMjYuNSAyMS41LTQ4IDQ4LTQ4ek00OCAxMjhsODAgMCAwIDY0LTY0IDAgMCAyNTYgMTkyIDAgMC0zMiA2NCAwIDAgNDhjMCAyNi41LTIxLjUgNDgtNDggNDhMNDggNTEyYy0yNi41IDAtNDgtMjEuNS00OC00OEwwIDE3NmMwLTI2LjUgMjEuNS00OCA0OC00OHoiLz48L3N2Zz4=);\n",
       "    background-repeat: no-repeat;\n",
       "    background-size: 14px 14px;\n",
       "    background-position: 0;\n",
       "    display: inline-block;\n",
       "    width: 14px;\n",
       "    height: 14px;\n",
       "    cursor: pointer;\n",
       "}\n",
       "</style><body><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=5,\n",
       "             estimator=Pipeline(steps=[(&#x27;vect&#x27;,\n",
       "                                        TfidfVectorizer(lowercase=False)),\n",
       "                                       (&#x27;clf&#x27;,\n",
       "                                        LogisticRegression(solver=&#x27;liblinear&#x27;))]),\n",
       "             n_jobs=1,\n",
       "             param_grid=[{&#x27;clf__C&#x27;: [1.0, 10.0], &#x27;clf__penalty&#x27;: [&#x27;l2&#x27;],\n",
       "                          &#x27;vect__ngram_range&#x27;: [(1, 1)],\n",
       "                          &#x27;vect__stop_words&#x27;: [None],\n",
       "                          &#x27;vect__tokenizer&#x27;: [&lt;function tokenizer at 0x78a20521ce50&gt;,\n",
       "                                              &lt;function tokenizer_porter at 0x78a205644040&gt;]},\n",
       "                         {&#x27;clf__C&#x27;: [1.0, 10.0], &#x27;clf__penalty&#x27;: [&#x27;l2&#x27;],\n",
       "                          &#x27;vect__ngram_range&#x27;: [(1, 1)], &#x27;vect__norm&#x27;: [None],\n",
       "                          &#x27;vect__stop_words&#x27;: [None],\n",
       "                          &#x27;vect__tokenizer&#x27;: [&lt;function tokenizer at 0x78a20521ce50&gt;,\n",
       "                                              &lt;function tokenizer_porter at 0x78a205644040&gt;],\n",
       "                          &#x27;vect__use_idf&#x27;: [False]}],\n",
       "             scoring=&#x27;accuracy&#x27;, verbose=2)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>GridSearchCV</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.7/modules/generated/sklearn.model_selection.GridSearchCV.html\">?<span>Documentation for GridSearchCV</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></div></label><div class=\"sk-toggleable__content fitted\" data-param-prefix=\"\">\n",
       "        <div class=\"estimator-table\">\n",
       "            <details>\n",
       "                <summary>Parameters</summary>\n",
       "                <table class=\"parameters-table\">\n",
       "                  <tbody>\n",
       "                    \n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('estimator',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">estimator&nbsp;</td>\n",
       "            <td class=\"value\">Pipeline(step...liblinear&#x27;))])</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('param_grid',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">param_grid&nbsp;</td>\n",
       "            <td class=\"value\">[{&#x27;clf__C&#x27;: [1.0, 10.0], &#x27;clf__penalty&#x27;: [&#x27;l2&#x27;], &#x27;vect__ngram_range&#x27;: [(1, ...)], &#x27;vect__stop_words&#x27;: [None], ...}, {&#x27;clf__C&#x27;: [1.0, 10.0], &#x27;clf__penalty&#x27;: [&#x27;l2&#x27;], &#x27;vect__ngram_range&#x27;: [(1, ...)], &#x27;vect__norm&#x27;: [None], ...}]</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('scoring',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">scoring&nbsp;</td>\n",
       "            <td class=\"value\">&#x27;accuracy&#x27;</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('n_jobs',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">n_jobs&nbsp;</td>\n",
       "            <td class=\"value\">1</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('refit',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">refit&nbsp;</td>\n",
       "            <td class=\"value\">True</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('cv',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">cv&nbsp;</td>\n",
       "            <td class=\"value\">5</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('verbose',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">verbose&nbsp;</td>\n",
       "            <td class=\"value\">2</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('pre_dispatch',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">pre_dispatch&nbsp;</td>\n",
       "            <td class=\"value\">&#x27;2*n_jobs&#x27;</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('error_score',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">error_score&nbsp;</td>\n",
       "            <td class=\"value\">nan</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('return_train_score',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">return_train_score&nbsp;</td>\n",
       "            <td class=\"value\">False</td>\n",
       "        </tr>\n",
       "    \n",
       "                  </tbody>\n",
       "                </table>\n",
       "            </details>\n",
       "        </div>\n",
       "    </div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" ><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>best_estimator_: Pipeline</div></div></label><div class=\"sk-toggleable__content fitted\" data-param-prefix=\"best_estimator___\"></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-7\" type=\"checkbox\" ><label for=\"sk-estimator-id-7\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>TfidfVectorizer</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.7/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html\">?<span>Documentation for TfidfVectorizer</span></a></div></label><div class=\"sk-toggleable__content fitted\" data-param-prefix=\"best_estimator___vect__\">\n",
       "        <div class=\"estimator-table\">\n",
       "            <details>\n",
       "                <summary>Parameters</summary>\n",
       "                <table class=\"parameters-table\">\n",
       "                  <tbody>\n",
       "                    \n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('input',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">input&nbsp;</td>\n",
       "            <td class=\"value\">&#x27;content&#x27;</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('encoding',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">encoding&nbsp;</td>\n",
       "            <td class=\"value\">&#x27;utf-8&#x27;</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('decode_error',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">decode_error&nbsp;</td>\n",
       "            <td class=\"value\">&#x27;strict&#x27;</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('strip_accents',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">strip_accents&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('lowercase',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">lowercase&nbsp;</td>\n",
       "            <td class=\"value\">False</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('preprocessor',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">preprocessor&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('tokenizer',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">tokenizer&nbsp;</td>\n",
       "            <td class=\"value\">&lt;function tok...x78a20521ce50&gt;</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('analyzer',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">analyzer&nbsp;</td>\n",
       "            <td class=\"value\">&#x27;word&#x27;</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('stop_words',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">stop_words&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('token_pattern',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">token_pattern&nbsp;</td>\n",
       "            <td class=\"value\">&#x27;(?u)\\\\b\\\\w\\\\w+\\\\b&#x27;</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('ngram_range',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">ngram_range&nbsp;</td>\n",
       "            <td class=\"value\">(1, ...)</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('max_df',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">max_df&nbsp;</td>\n",
       "            <td class=\"value\">1.0</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('min_df',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">min_df&nbsp;</td>\n",
       "            <td class=\"value\">1</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('max_features',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">max_features&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('vocabulary',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">vocabulary&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('binary',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">binary&nbsp;</td>\n",
       "            <td class=\"value\">False</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('dtype',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">dtype&nbsp;</td>\n",
       "            <td class=\"value\">&lt;class &#x27;numpy.float64&#x27;&gt;</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('norm',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">norm&nbsp;</td>\n",
       "            <td class=\"value\">&#x27;l2&#x27;</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('use_idf',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">use_idf&nbsp;</td>\n",
       "            <td class=\"value\">True</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('smooth_idf',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">smooth_idf&nbsp;</td>\n",
       "            <td class=\"value\">True</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('sublinear_tf',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">sublinear_tf&nbsp;</td>\n",
       "            <td class=\"value\">False</td>\n",
       "        </tr>\n",
       "    \n",
       "                  </tbody>\n",
       "                </table>\n",
       "            </details>\n",
       "        </div>\n",
       "    </div></div></div><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-8\" type=\"checkbox\" ><label for=\"sk-estimator-id-8\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>LogisticRegression</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.7/modules/generated/sklearn.linear_model.LogisticRegression.html\">?<span>Documentation for LogisticRegression</span></a></div></label><div class=\"sk-toggleable__content fitted\" data-param-prefix=\"best_estimator___clf__\">\n",
       "        <div class=\"estimator-table\">\n",
       "            <details>\n",
       "                <summary>Parameters</summary>\n",
       "                <table class=\"parameters-table\">\n",
       "                  <tbody>\n",
       "                    \n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('penalty',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">penalty&nbsp;</td>\n",
       "            <td class=\"value\">&#x27;l2&#x27;</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('dual',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">dual&nbsp;</td>\n",
       "            <td class=\"value\">False</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('tol',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">tol&nbsp;</td>\n",
       "            <td class=\"value\">0.0001</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('C',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">C&nbsp;</td>\n",
       "            <td class=\"value\">10.0</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('fit_intercept',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">fit_intercept&nbsp;</td>\n",
       "            <td class=\"value\">True</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('intercept_scaling',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">intercept_scaling&nbsp;</td>\n",
       "            <td class=\"value\">1</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('class_weight',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">class_weight&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('random_state',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">random_state&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('solver',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">solver&nbsp;</td>\n",
       "            <td class=\"value\">&#x27;liblinear&#x27;</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('max_iter',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">max_iter&nbsp;</td>\n",
       "            <td class=\"value\">100</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('multi_class',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">multi_class&nbsp;</td>\n",
       "            <td class=\"value\">&#x27;deprecated&#x27;</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('verbose',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">verbose&nbsp;</td>\n",
       "            <td class=\"value\">0</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('warm_start',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">warm_start&nbsp;</td>\n",
       "            <td class=\"value\">False</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('n_jobs',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">n_jobs&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('l1_ratio',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">l1_ratio&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "                  </tbody>\n",
       "                </table>\n",
       "            </details>\n",
       "        </div>\n",
       "    </div></div></div></div></div></div></div></div></div></div></div></div><script>function copyToClipboard(text, element) {\n",
       "    // Get the parameter prefix from the closest toggleable content\n",
       "    const toggleableContent = element.closest('.sk-toggleable__content');\n",
       "    const paramPrefix = toggleableContent ? toggleableContent.dataset.paramPrefix : '';\n",
       "    const fullParamName = paramPrefix ? `${paramPrefix}${text}` : text;\n",
       "\n",
       "    const originalStyle = element.style;\n",
       "    const computedStyle = window.getComputedStyle(element);\n",
       "    const originalWidth = computedStyle.width;\n",
       "    const originalHTML = element.innerHTML.replace('Copied!', '');\n",
       "\n",
       "    navigator.clipboard.writeText(fullParamName)\n",
       "        .then(() => {\n",
       "            element.style.width = originalWidth;\n",
       "            element.style.color = 'green';\n",
       "            element.innerHTML = \"Copied!\";\n",
       "\n",
       "            setTimeout(() => {\n",
       "                element.innerHTML = originalHTML;\n",
       "                element.style = originalStyle;\n",
       "            }, 2000);\n",
       "        })\n",
       "        .catch(err => {\n",
       "            console.error('Failed to copy:', err);\n",
       "            element.style.color = 'red';\n",
       "            element.innerHTML = \"Failed!\";\n",
       "            setTimeout(() => {\n",
       "                element.innerHTML = originalHTML;\n",
       "                element.style = originalStyle;\n",
       "            }, 2000);\n",
       "        });\n",
       "    return false;\n",
       "}\n",
       "\n",
       "document.querySelectorAll('.fa-regular.fa-copy').forEach(function(element) {\n",
       "    const toggleableContent = element.closest('.sk-toggleable__content');\n",
       "    const paramPrefix = toggleableContent ? toggleableContent.dataset.paramPrefix : '';\n",
       "    const paramName = element.parentElement.nextElementSibling.textContent.trim();\n",
       "    const fullParamName = paramPrefix ? `${paramPrefix}${paramName}` : paramName;\n",
       "\n",
       "    element.setAttribute('title', fullParamName);\n",
       "});\n",
       "</script></body>"
      ],
      "text/plain": [
       "GridSearchCV(cv=5,\n",
       "             estimator=Pipeline(steps=[('vect',\n",
       "                                        TfidfVectorizer(lowercase=False)),\n",
       "                                       ('clf',\n",
       "                                        LogisticRegression(solver='liblinear'))]),\n",
       "             n_jobs=1,\n",
       "             param_grid=[{'clf__C': [1.0, 10.0], 'clf__penalty': ['l2'],\n",
       "                          'vect__ngram_range': [(1, 1)],\n",
       "                          'vect__stop_words': [None],\n",
       "                          'vect__tokenizer': [<function tokenizer at 0x78a20521ce50>,\n",
       "                                              <function tokenizer_porter at 0x78a205644040>]},\n",
       "                         {'clf__C': [1.0, 10.0], 'clf__penalty': ['l2'],\n",
       "                          'vect__ngram_range': [(1, 1)], 'vect__norm': [None],\n",
       "                          'vect__stop_words': [None],\n",
       "                          'vect__tokenizer': [<function tokenizer at 0x78a20521ce50>,\n",
       "                                              <function tokenizer_porter at 0x78a205644040>],\n",
       "                          'vect__use_idf': [False]}],\n",
       "             scoring='accuracy', verbose=2)"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "tfidf = TfidfVectorizer(strip_accents = None,\n",
    "                        lowercase = False,\n",
    "                        preprocessor = None)\n",
    "small_param_grid = [\n",
    "    {\n",
    "        'vect__ngram_range': [(1,1)],\n",
    "        'vect__stop_words': [None],\n",
    "        'vect__tokenizer':[tokenizer, tokenizer_porter],\n",
    "        'clf__penalty':['l2'],\n",
    "        'clf__C':[1.0, 10.0]\n",
    "    },\n",
    "    {\n",
    "        'vect__ngram_range': [(1,1)],\n",
    "        'vect__stop_words': [None],\n",
    "        'vect__tokenizer':[tokenizer, tokenizer_porter],\n",
    "        'vect__use_idf': [False],\n",
    "        'vect__norm':[None],\n",
    "        'clf__penalty':['l2'],\n",
    "        'clf__C':[1.0, 10.0]\n",
    "    },\n",
    "]\n",
    "lr_tfidf = Pipeline([\n",
    "    ('vect', tfidf),\n",
    "    ('clf', LogisticRegression(solver='liblinear'))\n",
    "     ])\n",
    "gs_lr_tfidf = GridSearchCV(lr_tfidf, small_param_grid, scoring = 'accuracy', cv=5, verbose=2, n_jobs=1)\n",
    "gs_lr_tfidf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "472c1543-ab19-4831-9e93-be581e8f9196",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameter set: {'clf__C': 10.0, 'clf__penalty': 'l2', 'vect__ngram_range': (1, 1), 'vect__stop_words': None, 'vect__tokenizer': <function tokenizer at 0x78a20521ce50>}\n"
     ]
    }
   ],
   "source": [
    "print(f'Best parameter set: {gs_lr_tfidf.best_params_}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "ea90d0a5-92b4-4dee-891e-fe25287291cf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: jupyter_contrib_nbextensions in ./env/nllp/lib/python3.10/site-packages (0.7.0)\n",
      "Requirement already satisfied: ipython_genutils in ./env/nllp/lib/python3.10/site-packages (from jupyter_contrib_nbextensions) (0.2.0)\n",
      "Requirement already satisfied: jupyter_contrib_core>=0.3.3 in ./env/nllp/lib/python3.10/site-packages (from jupyter_contrib_nbextensions) (0.4.2)\n",
      "Requirement already satisfied: jupyter_core in ./env/nllp/lib/python3.10/site-packages (from jupyter_contrib_nbextensions) (5.8.1)\n",
      "Requirement already satisfied: jupyter_highlight_selected_word>=0.1.1 in ./env/nllp/lib/python3.10/site-packages (from jupyter_contrib_nbextensions) (0.2.0)\n",
      "Requirement already satisfied: jupyter_nbextensions_configurator>=0.4.0 in ./env/nllp/lib/python3.10/site-packages (from jupyter_contrib_nbextensions) (0.6.4)\n",
      "Requirement already satisfied: lxml in ./env/nllp/lib/python3.10/site-packages (from jupyter_contrib_nbextensions) (6.0.0)\n",
      "Requirement already satisfied: nbconvert>=6.0 in ./env/nllp/lib/python3.10/site-packages (from jupyter_contrib_nbextensions) (7.16.6)\n",
      "Requirement already satisfied: notebook>=6.0 in ./env/nllp/lib/python3.10/site-packages (from jupyter_contrib_nbextensions) (7.4.4)\n",
      "Requirement already satisfied: tornado in ./env/nllp/lib/python3.10/site-packages (from jupyter_contrib_nbextensions) (6.5.1)\n",
      "Requirement already satisfied: traitlets>=4.1 in ./env/nllp/lib/python3.10/site-packages (from jupyter_contrib_nbextensions) (5.14.3)\n",
      "Requirement already satisfied: setuptools in ./env/nllp/lib/python3.10/site-packages (from jupyter_contrib_core>=0.3.3->jupyter_contrib_nbextensions) (59.6.0)\n",
      "Requirement already satisfied: jupyter-server in ./env/nllp/lib/python3.10/site-packages (from jupyter_nbextensions_configurator>=0.4.0->jupyter_contrib_nbextensions) (2.16.0)\n",
      "Requirement already satisfied: pyyaml in ./env/nllp/lib/python3.10/site-packages (from jupyter_nbextensions_configurator>=0.4.0->jupyter_contrib_nbextensions) (6.0.2)\n",
      "Requirement already satisfied: nbformat>=5.7 in ./env/nllp/lib/python3.10/site-packages (from nbconvert>=6.0->jupyter_contrib_nbextensions) (5.10.4)\n",
      "Requirement already satisfied: nbclient>=0.5.0 in ./env/nllp/lib/python3.10/site-packages (from nbconvert>=6.0->jupyter_contrib_nbextensions) (0.10.2)\n",
      "Requirement already satisfied: pygments>=2.4.1 in ./env/nllp/lib/python3.10/site-packages (from nbconvert>=6.0->jupyter_contrib_nbextensions) (2.19.2)\n",
      "Requirement already satisfied: jupyterlab-pygments in ./env/nllp/lib/python3.10/site-packages (from nbconvert>=6.0->jupyter_contrib_nbextensions) (0.3.0)\n",
      "Requirement already satisfied: jinja2>=3.0 in ./env/nllp/lib/python3.10/site-packages (from nbconvert>=6.0->jupyter_contrib_nbextensions) (3.1.6)\n",
      "Requirement already satisfied: bleach[css]!=5.0.0 in ./env/nllp/lib/python3.10/site-packages (from nbconvert>=6.0->jupyter_contrib_nbextensions) (6.2.0)\n",
      "Requirement already satisfied: packaging in ./env/nllp/lib/python3.10/site-packages (from nbconvert>=6.0->jupyter_contrib_nbextensions) (25.0)\n",
      "Requirement already satisfied: defusedxml in ./env/nllp/lib/python3.10/site-packages (from nbconvert>=6.0->jupyter_contrib_nbextensions) (0.7.1)\n",
      "Requirement already satisfied: markupsafe>=2.0 in ./env/nllp/lib/python3.10/site-packages (from nbconvert>=6.0->jupyter_contrib_nbextensions) (3.0.2)\n",
      "Requirement already satisfied: pandocfilters>=1.4.1 in ./env/nllp/lib/python3.10/site-packages (from nbconvert>=6.0->jupyter_contrib_nbextensions) (1.5.1)\n",
      "Requirement already satisfied: beautifulsoup4 in ./env/nllp/lib/python3.10/site-packages (from nbconvert>=6.0->jupyter_contrib_nbextensions) (4.13.4)\n",
      "Requirement already satisfied: mistune<4,>=2.0.3 in ./env/nllp/lib/python3.10/site-packages (from nbconvert>=6.0->jupyter_contrib_nbextensions) (3.1.3)\n",
      "Requirement already satisfied: platformdirs>=2.5 in ./env/nllp/lib/python3.10/site-packages (from jupyter_core->jupyter_contrib_nbextensions) (4.3.8)\n",
      "Requirement already satisfied: jupyterlab<4.5,>=4.4.4 in ./env/nllp/lib/python3.10/site-packages (from notebook>=6.0->jupyter_contrib_nbextensions) (4.4.4)\n",
      "Requirement already satisfied: notebook-shim<0.3,>=0.2 in ./env/nllp/lib/python3.10/site-packages (from notebook>=6.0->jupyter_contrib_nbextensions) (0.2.4)\n",
      "Requirement already satisfied: jupyterlab-server<3,>=2.27.1 in ./env/nllp/lib/python3.10/site-packages (from notebook>=6.0->jupyter_contrib_nbextensions) (2.27.3)\n",
      "Requirement already satisfied: webencodings in ./env/nllp/lib/python3.10/site-packages (from bleach[css]!=5.0.0->nbconvert>=6.0->jupyter_contrib_nbextensions) (0.5.1)\n",
      "Requirement already satisfied: tinycss2<1.5,>=1.1.0 in ./env/nllp/lib/python3.10/site-packages (from bleach[css]!=5.0.0->nbconvert>=6.0->jupyter_contrib_nbextensions) (1.4.0)\n",
      "Requirement already satisfied: send2trash>=1.8.2 in ./env/nllp/lib/python3.10/site-packages (from jupyter-server->jupyter_nbextensions_configurator>=0.4.0->jupyter_contrib_nbextensions) (1.8.3)\n",
      "Requirement already satisfied: websocket-client>=1.7 in ./env/nllp/lib/python3.10/site-packages (from jupyter-server->jupyter_nbextensions_configurator>=0.4.0->jupyter_contrib_nbextensions) (1.8.0)\n",
      "Requirement already satisfied: jupyter-client>=7.4.4 in ./env/nllp/lib/python3.10/site-packages (from jupyter-server->jupyter_nbextensions_configurator>=0.4.0->jupyter_contrib_nbextensions) (8.6.3)\n",
      "Requirement already satisfied: overrides>=5.0 in ./env/nllp/lib/python3.10/site-packages (from jupyter-server->jupyter_nbextensions_configurator>=0.4.0->jupyter_contrib_nbextensions) (7.7.0)\n",
      "Requirement already satisfied: pyzmq>=24 in ./env/nllp/lib/python3.10/site-packages (from jupyter-server->jupyter_nbextensions_configurator>=0.4.0->jupyter_contrib_nbextensions) (27.0.0)\n",
      "Requirement already satisfied: anyio>=3.1.0 in ./env/nllp/lib/python3.10/site-packages (from jupyter-server->jupyter_nbextensions_configurator>=0.4.0->jupyter_contrib_nbextensions) (4.9.0)\n",
      "Requirement already satisfied: prometheus-client>=0.9 in ./env/nllp/lib/python3.10/site-packages (from jupyter-server->jupyter_nbextensions_configurator>=0.4.0->jupyter_contrib_nbextensions) (0.22.1)\n",
      "Requirement already satisfied: jupyter-server-terminals>=0.4.4 in ./env/nllp/lib/python3.10/site-packages (from jupyter-server->jupyter_nbextensions_configurator>=0.4.0->jupyter_contrib_nbextensions) (0.5.3)\n",
      "Requirement already satisfied: terminado>=0.8.3 in ./env/nllp/lib/python3.10/site-packages (from jupyter-server->jupyter_nbextensions_configurator>=0.4.0->jupyter_contrib_nbextensions) (0.18.1)\n",
      "Requirement already satisfied: argon2-cffi>=21.1 in ./env/nllp/lib/python3.10/site-packages (from jupyter-server->jupyter_nbextensions_configurator>=0.4.0->jupyter_contrib_nbextensions) (25.1.0)\n",
      "Requirement already satisfied: jupyter-events>=0.11.0 in ./env/nllp/lib/python3.10/site-packages (from jupyter-server->jupyter_nbextensions_configurator>=0.4.0->jupyter_contrib_nbextensions) (0.12.0)\n",
      "Requirement already satisfied: ipykernel>=6.5.0 in ./env/nllp/lib/python3.10/site-packages (from jupyterlab<4.5,>=4.4.4->notebook>=6.0->jupyter_contrib_nbextensions) (6.29.5)\n",
      "Requirement already satisfied: httpx>=0.25.0 in ./env/nllp/lib/python3.10/site-packages (from jupyterlab<4.5,>=4.4.4->notebook>=6.0->jupyter_contrib_nbextensions) (0.28.1)\n",
      "Requirement already satisfied: async-lru>=1.0.0 in ./env/nllp/lib/python3.10/site-packages (from jupyterlab<4.5,>=4.4.4->notebook>=6.0->jupyter_contrib_nbextensions) (2.0.5)\n",
      "Requirement already satisfied: tomli>=1.2.2 in ./env/nllp/lib/python3.10/site-packages (from jupyterlab<4.5,>=4.4.4->notebook>=6.0->jupyter_contrib_nbextensions) (2.2.1)\n",
      "Requirement already satisfied: jupyter-lsp>=2.0.0 in ./env/nllp/lib/python3.10/site-packages (from jupyterlab<4.5,>=4.4.4->notebook>=6.0->jupyter_contrib_nbextensions) (2.2.5)\n",
      "Requirement already satisfied: json5>=0.9.0 in ./env/nllp/lib/python3.10/site-packages (from jupyterlab-server<3,>=2.27.1->notebook>=6.0->jupyter_contrib_nbextensions) (0.12.0)\n",
      "Requirement already satisfied: babel>=2.10 in ./env/nllp/lib/python3.10/site-packages (from jupyterlab-server<3,>=2.27.1->notebook>=6.0->jupyter_contrib_nbextensions) (2.17.0)\n",
      "Requirement already satisfied: jsonschema>=4.18.0 in ./env/nllp/lib/python3.10/site-packages (from jupyterlab-server<3,>=2.27.1->notebook>=6.0->jupyter_contrib_nbextensions) (4.24.0)\n",
      "Requirement already satisfied: requests>=2.31 in ./env/nllp/lib/python3.10/site-packages (from jupyterlab-server<3,>=2.27.1->notebook>=6.0->jupyter_contrib_nbextensions) (2.32.4)\n",
      "Requirement already satisfied: typing-extensions in ./env/nllp/lib/python3.10/site-packages (from mistune<4,>=2.0.3->nbconvert>=6.0->jupyter_contrib_nbextensions) (4.14.1)\n",
      "Requirement already satisfied: fastjsonschema>=2.15 in ./env/nllp/lib/python3.10/site-packages (from nbformat>=5.7->nbconvert>=6.0->jupyter_contrib_nbextensions) (2.21.1)\n",
      "Requirement already satisfied: soupsieve>1.2 in ./env/nllp/lib/python3.10/site-packages (from beautifulsoup4->nbconvert>=6.0->jupyter_contrib_nbextensions) (2.7)\n",
      "Requirement already satisfied: sniffio>=1.1 in ./env/nllp/lib/python3.10/site-packages (from anyio>=3.1.0->jupyter-server->jupyter_nbextensions_configurator>=0.4.0->jupyter_contrib_nbextensions) (1.3.1)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in ./env/nllp/lib/python3.10/site-packages (from anyio>=3.1.0->jupyter-server->jupyter_nbextensions_configurator>=0.4.0->jupyter_contrib_nbextensions) (1.3.0)\n",
      "Requirement already satisfied: idna>=2.8 in ./env/nllp/lib/python3.10/site-packages (from anyio>=3.1.0->jupyter-server->jupyter_nbextensions_configurator>=0.4.0->jupyter_contrib_nbextensions) (3.10)\n",
      "Requirement already satisfied: argon2-cffi-bindings in ./env/nllp/lib/python3.10/site-packages (from argon2-cffi>=21.1->jupyter-server->jupyter_nbextensions_configurator>=0.4.0->jupyter_contrib_nbextensions) (21.2.0)\n",
      "Requirement already satisfied: certifi in ./env/nllp/lib/python3.10/site-packages (from httpx>=0.25.0->jupyterlab<4.5,>=4.4.4->notebook>=6.0->jupyter_contrib_nbextensions) (2025.7.14)\n",
      "Requirement already satisfied: httpcore==1.* in ./env/nllp/lib/python3.10/site-packages (from httpx>=0.25.0->jupyterlab<4.5,>=4.4.4->notebook>=6.0->jupyter_contrib_nbextensions) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in ./env/nllp/lib/python3.10/site-packages (from httpcore==1.*->httpx>=0.25.0->jupyterlab<4.5,>=4.4.4->notebook>=6.0->jupyter_contrib_nbextensions) (0.16.0)\n",
      "Requirement already satisfied: debugpy>=1.6.5 in ./env/nllp/lib/python3.10/site-packages (from ipykernel>=6.5.0->jupyterlab<4.5,>=4.4.4->notebook>=6.0->jupyter_contrib_nbextensions) (1.8.14)\n",
      "Requirement already satisfied: matplotlib-inline>=0.1 in ./env/nllp/lib/python3.10/site-packages (from ipykernel>=6.5.0->jupyterlab<4.5,>=4.4.4->notebook>=6.0->jupyter_contrib_nbextensions) (0.1.7)\n",
      "Requirement already satisfied: psutil in ./env/nllp/lib/python3.10/site-packages (from ipykernel>=6.5.0->jupyterlab<4.5,>=4.4.4->notebook>=6.0->jupyter_contrib_nbextensions) (7.0.0)\n",
      "Requirement already satisfied: comm>=0.1.1 in ./env/nllp/lib/python3.10/site-packages (from ipykernel>=6.5.0->jupyterlab<4.5,>=4.4.4->notebook>=6.0->jupyter_contrib_nbextensions) (0.2.2)\n",
      "Requirement already satisfied: nest-asyncio in ./env/nllp/lib/python3.10/site-packages (from ipykernel>=6.5.0->jupyterlab<4.5,>=4.4.4->notebook>=6.0->jupyter_contrib_nbextensions) (1.6.0)\n",
      "Requirement already satisfied: ipython>=7.23.1 in ./env/nllp/lib/python3.10/site-packages (from ipykernel>=6.5.0->jupyterlab<4.5,>=4.4.4->notebook>=6.0->jupyter_contrib_nbextensions) (8.37.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in ./env/nllp/lib/python3.10/site-packages (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.27.1->notebook>=6.0->jupyter_contrib_nbextensions) (2025.4.1)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in ./env/nllp/lib/python3.10/site-packages (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.27.1->notebook>=6.0->jupyter_contrib_nbextensions) (0.26.0)\n",
      "Requirement already satisfied: attrs>=22.2.0 in ./env/nllp/lib/python3.10/site-packages (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.27.1->notebook>=6.0->jupyter_contrib_nbextensions) (25.3.0)\n",
      "Requirement already satisfied: referencing>=0.28.4 in ./env/nllp/lib/python3.10/site-packages (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.27.1->notebook>=6.0->jupyter_contrib_nbextensions) (0.36.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in ./env/nllp/lib/python3.10/site-packages (from jupyter-client>=7.4.4->jupyter-server->jupyter_nbextensions_configurator>=0.4.0->jupyter_contrib_nbextensions) (2.9.0.post0)\n",
      "Requirement already satisfied: rfc3986-validator>=0.1.1 in ./env/nllp/lib/python3.10/site-packages (from jupyter-events>=0.11.0->jupyter-server->jupyter_nbextensions_configurator>=0.4.0->jupyter_contrib_nbextensions) (0.1.1)\n",
      "Requirement already satisfied: rfc3339-validator in ./env/nllp/lib/python3.10/site-packages (from jupyter-events>=0.11.0->jupyter-server->jupyter_nbextensions_configurator>=0.4.0->jupyter_contrib_nbextensions) (0.1.4)\n",
      "Requirement already satisfied: python-json-logger>=2.0.4 in ./env/nllp/lib/python3.10/site-packages (from jupyter-events>=0.11.0->jupyter-server->jupyter_nbextensions_configurator>=0.4.0->jupyter_contrib_nbextensions) (3.3.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in ./env/nllp/lib/python3.10/site-packages (from requests>=2.31->jupyterlab-server<3,>=2.27.1->notebook>=6.0->jupyter_contrib_nbextensions) (3.4.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./env/nllp/lib/python3.10/site-packages (from requests>=2.31->jupyterlab-server<3,>=2.27.1->notebook>=6.0->jupyter_contrib_nbextensions) (2.5.0)\n",
      "Requirement already satisfied: ptyprocess in ./env/nllp/lib/python3.10/site-packages (from terminado>=0.8.3->jupyter-server->jupyter_nbextensions_configurator>=0.4.0->jupyter_contrib_nbextensions) (0.7.0)\n",
      "Requirement already satisfied: jedi>=0.16 in ./env/nllp/lib/python3.10/site-packages (from ipython>=7.23.1->ipykernel>=6.5.0->jupyterlab<4.5,>=4.4.4->notebook>=6.0->jupyter_contrib_nbextensions) (0.19.2)\n",
      "Requirement already satisfied: decorator in ./env/nllp/lib/python3.10/site-packages (from ipython>=7.23.1->ipykernel>=6.5.0->jupyterlab<4.5,>=4.4.4->notebook>=6.0->jupyter_contrib_nbextensions) (5.2.1)\n",
      "Requirement already satisfied: stack_data in ./env/nllp/lib/python3.10/site-packages (from ipython>=7.23.1->ipykernel>=6.5.0->jupyterlab<4.5,>=4.4.4->notebook>=6.0->jupyter_contrib_nbextensions) (0.6.3)\n",
      "Requirement already satisfied: prompt_toolkit<3.1.0,>=3.0.41 in ./env/nllp/lib/python3.10/site-packages (from ipython>=7.23.1->ipykernel>=6.5.0->jupyterlab<4.5,>=4.4.4->notebook>=6.0->jupyter_contrib_nbextensions) (3.0.51)\n",
      "Requirement already satisfied: pexpect>4.3 in ./env/nllp/lib/python3.10/site-packages (from ipython>=7.23.1->ipykernel>=6.5.0->jupyterlab<4.5,>=4.4.4->notebook>=6.0->jupyter_contrib_nbextensions) (4.9.0)\n",
      "Requirement already satisfied: fqdn in ./env/nllp/lib/python3.10/site-packages (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.27.1->notebook>=6.0->jupyter_contrib_nbextensions) (1.5.1)\n",
      "Requirement already satisfied: jsonpointer>1.13 in ./env/nllp/lib/python3.10/site-packages (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.27.1->notebook>=6.0->jupyter_contrib_nbextensions) (3.0.0)\n",
      "Requirement already satisfied: webcolors>=24.6.0 in ./env/nllp/lib/python3.10/site-packages (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.27.1->notebook>=6.0->jupyter_contrib_nbextensions) (24.11.1)\n",
      "Requirement already satisfied: uri-template in ./env/nllp/lib/python3.10/site-packages (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.27.1->notebook>=6.0->jupyter_contrib_nbextensions) (1.3.0)\n",
      "Requirement already satisfied: isoduration in ./env/nllp/lib/python3.10/site-packages (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.27.1->notebook>=6.0->jupyter_contrib_nbextensions) (20.11.0)\n",
      "Requirement already satisfied: six>=1.5 in ./env/nllp/lib/python3.10/site-packages (from python-dateutil>=2.8.2->jupyter-client>=7.4.4->jupyter-server->jupyter_nbextensions_configurator>=0.4.0->jupyter_contrib_nbextensions) (1.17.0)\n",
      "Requirement already satisfied: cffi>=1.0.1 in ./env/nllp/lib/python3.10/site-packages (from argon2-cffi-bindings->argon2-cffi>=21.1->jupyter-server->jupyter_nbextensions_configurator>=0.4.0->jupyter_contrib_nbextensions) (1.17.1)\n",
      "Requirement already satisfied: pycparser in ./env/nllp/lib/python3.10/site-packages (from cffi>=1.0.1->argon2-cffi-bindings->argon2-cffi>=21.1->jupyter-server->jupyter_nbextensions_configurator>=0.4.0->jupyter_contrib_nbextensions) (2.22)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.4 in ./env/nllp/lib/python3.10/site-packages (from jedi>=0.16->ipython>=7.23.1->ipykernel>=6.5.0->jupyterlab<4.5,>=4.4.4->notebook>=6.0->jupyter_contrib_nbextensions) (0.8.4)\n",
      "Requirement already satisfied: wcwidth in ./env/nllp/lib/python3.10/site-packages (from prompt_toolkit<3.1.0,>=3.0.41->ipython>=7.23.1->ipykernel>=6.5.0->jupyterlab<4.5,>=4.4.4->notebook>=6.0->jupyter_contrib_nbextensions) (0.2.13)\n",
      "Requirement already satisfied: arrow>=0.15.0 in ./env/nllp/lib/python3.10/site-packages (from isoduration->jsonschema>=4.18.0->jupyterlab-server<3,>=2.27.1->notebook>=6.0->jupyter_contrib_nbextensions) (1.3.0)\n",
      "Requirement already satisfied: asttokens>=2.1.0 in ./env/nllp/lib/python3.10/site-packages (from stack_data->ipython>=7.23.1->ipykernel>=6.5.0->jupyterlab<4.5,>=4.4.4->notebook>=6.0->jupyter_contrib_nbextensions) (3.0.0)\n",
      "Requirement already satisfied: pure-eval in ./env/nllp/lib/python3.10/site-packages (from stack_data->ipython>=7.23.1->ipykernel>=6.5.0->jupyterlab<4.5,>=4.4.4->notebook>=6.0->jupyter_contrib_nbextensions) (0.2.3)\n",
      "Requirement already satisfied: executing>=1.2.0 in ./env/nllp/lib/python3.10/site-packages (from stack_data->ipython>=7.23.1->ipykernel>=6.5.0->jupyterlab<4.5,>=4.4.4->notebook>=6.0->jupyter_contrib_nbextensions) (2.2.0)\n",
      "Requirement already satisfied: types-python-dateutil>=2.8.10 in ./env/nllp/lib/python3.10/site-packages (from arrow>=0.15.0->isoduration->jsonschema>=4.18.0->jupyterlab-server<3,>=2.27.1->notebook>=6.0->jupyter_contrib_nbextensions) (2.9.0.20250708)\n"
     ]
    }
   ],
   "source": [
    "!pip install jupyter_contrib_nbextensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "17484576-9354-47fc-a11e-0d5acc854c9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV Accuracy: 0.891\n",
      "Test accuracy: 0.897\n"
     ]
    }
   ],
   "source": [
    "print(f'CV Accuracy: {gs_lr_tfidf.best_score_:.3f}')\n",
    "clf = gs_lr_tfidf.best_estimator_\n",
    "print(f'Test accuracy: {clf.score(X_test, y_test):.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "9f8cf476-904c-418d-9bf0-6c32bb1bb8dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "### need to learn naive bayes classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4628e08-b7aa-43e2-92af-d7cd04cfe0fd",
   "metadata": {},
   "source": [
    "## working with bigger data - online algorithms and out-of-core learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "7bf73480-d390-4762-9551-af4d53d978de",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "stop = stopwords.words(\n",
    "    'english'\n",
    ")\n",
    "\n",
    "def tokenizer(text):\n",
    "    text = re.sub('<[^>]*>', '', text)\n",
    "    emoticons = re.findall('(?::|;|=)(?:-)?(?:\\)|\\(|D|P)',text.lower())\n",
    "    text = re.sub('[\\W]+', ' ', text.lower()) + ' '.join(emoticons).replace('-', '')\n",
    "    tokenized = [w for w in text.split() if w not in stop]\n",
    "    return tokenized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "ac6474a1-0fdd-4f0b-bf88-bcfa2aea938f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stream_docs(path):\n",
    "    with open(path, 'r', encoding='utf-8') as csv:\n",
    "        next(csv)\n",
    "        for line in csv:\n",
    "            text, label = line[:-3], int(line[-2])\n",
    "            yield text, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "6364a89c-1d43-4bff-868c-e8f93e77b29c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('\"In 1974, the teenager Martha Moxley (Maggie Grace) moves to the high-class area of Belle Haven, Greenwich, Connecticut. On the Mischief Night, eve of Halloween, she was murdered in the backyard of her house and her murder remained unsolved. Twenty-two years later, the writer Mark Fuhrman (Christopher Meloni), who is a former LA detective that has fallen in disgrace for perjury in O.J. Simpson trial and moved to Idaho, decides to investigate the case with his partner Stephen Weeks (Andrew Mitchell) with the purpose of writing a book. The locals squirm and do not welcome them, but with the support of the retired detective Steve Carroll (Robert Forster) that was in charge of the investigation in the 70\\'s, they discover the criminal and a net of power and money to cover the murder.<br /><br />\"\"Murder in Greenwich\"\" is a good TV movie, with the true story of a murder of a fifteen years old girl that was committed by a wealthy teenager whose mother was a Kennedy. The powerful and rich family used their influence to cover the murder for more than twenty years. However, a snoopy detective and convicted perjurer in disgrace was able to disclose how the hideous crime was committed. The screenplay shows the investigation of Mark and the last days of Martha in parallel, but there is a lack of the emotion in the dramatization. My vote is seven.<br /><br />Title (Brazil): Not Available\"',\n",
       " 1)"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(stream_docs(path='movie_data.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "823bccf8-166e-4bab-8516-115b0265f52b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_minibatch(doc_stream, size):\n",
    "    docs, y =[], []\n",
    "    try:\n",
    "        for _ in range(size):\n",
    "            text, label = next(doc_stream)\n",
    "            docs.append(text)\n",
    "            y.append(label)\n",
    "    except StopIteration:\n",
    "        return None, None\n",
    "    return docs,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "0984536c-7d37-4728-944d-93bb9fe29cf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import HashingVectorizer\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "vect = HashingVectorizer(decode_error = 'ignore',\n",
    "                        n_features = 2**21,\n",
    "                         tokenizer = tokenizer,\n",
    "                         preprocessor = None\n",
    "                        )\n",
    "clf = SGDClassifier(loss='log_loss', random_state=1)\n",
    "doc_stream = stream_docs(path = \"movie_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "46df6724-9513-457e-a280-b0202c68898f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0% [##############################] 100% | ETA: 00:00:00\n",
      "Total time elapsed: 00:00:18\n"
     ]
    }
   ],
   "source": [
    "import pyprind\n",
    "pbar = pyprind.ProgBar(45)\n",
    "classes = np.array([0,1])\n",
    "for _ in range(45):\n",
    "    X_train, y_train = get_minibatch(doc_stream, size = 1000)\n",
    "    if not X_train:\n",
    "        break\n",
    "    X_train = vect.transform(X_train)\n",
    "    clf.partial_fit(X_train, y_train, classes=classes)\n",
    "    pbar.update()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "693df92f-585f-4bd4-a266-30df4c93a26e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.868\n"
     ]
    }
   ],
   "source": [
    "X_test, y_test = get_minibatch(doc_stream, size=5000)\n",
    "X_test = vect.transform(X_test)\n",
    "print(f'Accuracy: {clf.score(X_test, y_test):.3f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "8cc986ea-5879-48de-83c9-714ca4a46efa",
   "metadata": {},
   "outputs": [],
   "source": [
    "### need to understand the word2vec model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "5ec48a44-f0ed-4cdd-b306-c95546f2fab8",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = clf.partial_fit(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "8c534792-e301-4889-bf09-e047cd61b41e",
   "metadata": {},
   "outputs": [],
   "source": [
    "## topic modeling with latent dirichlet allocation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "c2d96805-db9c-4e99-a7e5-f4e8f0071395",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('movie_data.csv',encoding='utf-8')\n",
    "# df = df.rename(columns={})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "b346f16c-13ef-4f65-93f2-91f24d9392aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>In 1974, the teenager Martha Moxley (Maggie Gr...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>OK... so... I really like Kris Kristofferson a...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>***SPOILER*** Do not read this, if you think a...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>hi for all the people who have seen this wonde...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I recently bought the DVD, forgetting just how...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review  sentiment\n",
       "0  In 1974, the teenager Martha Moxley (Maggie Gr...          1\n",
       "1  OK... so... I really like Kris Kristofferson a...          0\n",
       "2  ***SPOILER*** Do not read this, if you think a...          0\n",
       "3  hi for all the people who have seen this wonde...          1\n",
       "4  I recently bought the DVD, forgetting just how...          0"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "05648a0d-e2ce-4ba2-aafe-759e67b22305",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "count = CountVectorizer(stop_words = 'english', max_df=1, max_features=5000)\n",
    "\n",
    "X = count.fit_transform(df['review'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "44745996-c972-43d9-9246-8734adb6cdff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5000"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(count.vocabulary_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "efad426b-e6f0-4d2b-9648-5e14073a6da6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "\n",
    "lda = LatentDirichletAllocation(n_components = 10, random_state= 123, learning_method='batch')\n",
    "\n",
    "X_topics = lda.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "6373d19e-84cc-4970-9347-9bdaf0383521",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 5000)"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lda.components_.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "9e6fe2e8-d2dc-4bef-89a0-14041a088820",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic 1:\n",
      "trivialboring kazaf liliom weedon jeffs\n",
      "Topic 2:\n",
      "prag blacksnake cabell anouska lesseos\n",
      "Topic 3:\n",
      "keitaro tronje moores hollins sampredo\n",
      "Topic 4:\n",
      "shlomi floraine hayakawa hongshen norliss\n",
      "Topic 5:\n",
      "fanshawe lematt shinae gant kazuhiro\n",
      "Topic 6:\n",
      "uzumakis tucsos narvo tmtm chassidic\n",
      "Topic 7:\n",
      "hanka rosarios perú moag crystina\n",
      "Topic 8:\n",
      "tetsurô bazza iameracing tagge jouissance\n",
      "Topic 9:\n",
      "montero tobell numar ramar tsa\n",
      "Topic 10:\n",
      "allana havers rf frewer chise\n"
     ]
    }
   ],
   "source": [
    "n_top_words = 5\n",
    "\n",
    "feature_names = count.get_feature_names_out()\n",
    "for topic_idx, topic in enumerate(lda.components_):\n",
    "    print(f'Topic {(topic_idx + 1)}:')\n",
    "    print(' '.join([feature_names[i] for i in topic.argsort()[:-n_top_words-1:-1]]))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "0ba199ac-adee-4099-8add-b137668ee6ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Horror Movie #1\n",
      "For me the only reason for having a look at this remake was to see how bad and funny it could be. There was no doubt about it being funny and bad, because I had seen \"Voyna i mir\" (1968). Shall we begin? Here we go...<br /><br />Robert Dornhelm & Brendan Donnison's Pierre Bezukhov - a lean fellow th ...\n",
      "\n",
      " Horror Movie #2\n",
      "\"Only the Valiant\" qualifies as a gritty good western. This Gregory Peck cavalry versus the Indians oater is a solemn suicide mission without a trace of humor. Veteran director Gordon Douglas has helmed a grim, harrowing outdoors epic with an ideal cast of tough guys under considerable pressure; eve ...\n",
      "\n",
      " Horror Movie #3\n",
      "Uzumaki, which translates into \"spirals\", arriving within this new wave of Asian Horror films following such hits like Ringu, Ju-On and The Eye (two of them with remakes.. and much more coming like Dark Water and Tale of Two Sisters), falls short of the spooky, supernatural thriller element so chara ...\n"
     ]
    }
   ],
   "source": [
    "horror = X_topics[:,5].argsort()[::-1]\n",
    "\n",
    "for iter_idx, movie_idx in enumerate(horror[:3]):\n",
    "    print(f\"\\n Horror Movie #{(iter_idx+1)}\")\n",
    "    print(df['review'][movie_idx][:300], \"...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48b6785e-45c2-4857-b5dd-42ecb657f07d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b40ec6e9-d2b8-4e79-a7ae-5149408de263",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "819ebd66-2f71-46df-8581-cf862fefa782",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
